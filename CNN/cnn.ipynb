{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr2mSxr1YyxY"
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "import numpy as np\n",
        "\n",
        "train_dir = '../input/fruits/Fruits_1/Training'\n",
        "test_dir = '../input/fruits/Fruits_1/Test'\n",
        "\n",
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    files = np.array(data['filenames'])\n",
        "    targets = np.array(data['target'])\n",
        "    target_labels = np.array(data['target_names'])\n",
        "    return files,targets,target_labels\n",
        "    \n",
        "x_train, y_train,target_labels = load_dataset(train_dir)\n",
        "x_test, y_test,_ = load_dataset(test_dir)\n",
        "print('Loading complete!')\n",
        "\n",
        "print('Training set size : ' , x_train.shape[0])\n",
        "print('Testing set size : ', x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM6hJfMzYzx6"
      },
      "source": [
        "no_of_classes = len(np.unique(y_train))\n",
        "no_of_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfu2NweUY2XM"
      },
      "source": [
        "print(y_train[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzqEE2QIY5OW"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train,no_of_classes)\n",
        "y_test = np_utils.to_categorical(y_test,no_of_classes)\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHuNydniY7mf"
      },
      "source": [
        "x_test,x_valid = x_test[3500:],x_test[:3500]\n",
        "y_test,y_vaild = y_test[3500:],y_test[:3500]\n",
        "print('Vaildation X : ',x_valid.shape)\n",
        "print('Vaildation y :',y_vaild.shape)\n",
        "print('Test X : ',x_test.shape)\n",
        "print('Test y : ',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDBXHJVhY-fG"
      },
      "source": [
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "\n",
        "def convert_image_to_array(files):\n",
        "    images_as_array=[]\n",
        "    for file in files:\n",
        "        # Convert to Numpy Array\n",
        "        images_as_array.append(img_to_array(load_img(file)))\n",
        "    return images_as_array\n",
        "\n",
        "x_train = np.array(convert_image_to_array(x_train))\n",
        "print('Training set shape : ',x_train.shape)\n",
        "\n",
        "x_valid = np.array(convert_image_to_array(x_valid))\n",
        "print('Validation set shape : ',x_valid.shape)\n",
        "\n",
        "x_test = np.array(convert_image_to_array(x_test))\n",
        "print('Test set shape : ',x_test.shape)\n",
        "\n",
        "print('1st training image shape ',x_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZPCcxC3ZBvM"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 256,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(41,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ZSH_VvZHhd"
      },
      "source": [
        "Model: \"sequential_4\"\n",
        "_________________________________________________________________\n",
        "**Layer (type)**           |      **Output Shape**       |       **Param #** \n",
        "_________________________________________________________________\n",
        "conv2d_16 (Conv2D)        |   (None, 100, 100, 16)    |  208       \n",
        "_________________________________________________________________\n",
        "activation_7 (Activation)  |  (None, 100, 100, 16)     | 0         \n",
        "_________________________________________________________________\n",
        "max_pooling2d_16 (MaxPooling) | (None, 50, 50, 16)      |  0         \n",
        "_________________________________________________________________\n",
        "conv2d_17 (Conv2D)           | (None, 50, 50, 32)       | 2080      \n",
        "_________________________________________________________________\n",
        "max_pooling2d_17 (MaxPooling | (None, 25, 25, 32)       | 0         \n",
        "_________________________________________________________________\n",
        "conv2d_18 (Conv2D)           | (None, 25, 25, 64)       | 8256      \n",
        "_________________________________________________________________\n",
        "max_pooling2d_18 (MaxPooling | (None, 12, 12, 64)       | 0         \n",
        "_________________________________________________________________\n",
        "conv2d_19 (Conv2D)          | (None, 12, 12, 128)       | 32896     \n",
        "_________________________________________________________________\n",
        "max_pooling2d_19 (MaxPooling | (None, 6, 6, 128)       |  0         \n",
        "_________________________________________________________________\n",
        "conv2d_20 (Conv2D)          | (None, 6, 6, 256)        | 131328    \n",
        "_________________________________________________________________\n",
        "max_pooling2d_20 (MaxPooling | (None, 3, 3, 256)       |  0         \n",
        "_________________________________________________________________\n",
        "dropout_7 (Dropout)         | (None, 3, 3, 256)        | 0         \n",
        "_________________________________________________________________\n",
        "flatten_4 (Flatten)          | (None, 2304)            | 0         \n",
        "_________________________________________________________________\n",
        "dense_7 (Dense)              |(None, 150)              | 345750    \n",
        "_________________________________________________________________\n",
        "activation_8 (Activation)    |(None, 150)              | 0         \n",
        "_________________________________________________________________\n",
        "dropout_8 (Dropout)          |(None, 150)              | 0         \n",
        "_________________________________________________________________\n",
        "dense_8 (Dense)            |  (None, 41)               | 6191      \n",
        "_________________________________________________________________\n",
        "Total params: 526,709 \n",
        "\n",
        "Trainable params: 526,709\n",
        "\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AiKcVgwZE1L"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print('Compiled!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc15-t5vaLOc"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "batch_size = 50\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath = 'cnn.hdf5', verbose = 1, save_best_only = True)\n",
        "\n",
        "history = model.fit(x_train,y_train,\n",
        "        batch_size = 50,\n",
        "        epochs=15,\n",
        "        validation_data=(x_valid, y_vaild),\n",
        "        callbacks = [checkpointer],\n",
        "                    verbose=2,shuffle=True\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VT6Ncz_aMLE"
      },
      "source": [
        "model.load_weights('cnn.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXtGBjEzaTB3"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIGqQnH7aVmT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}